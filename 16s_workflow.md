# 16S workflow

## Quality filter data

Only using forward reads

**Prinseq**
```
for file in *R1*.fastq;
do
prinseq-lite.pl -fastq ${file} \
-out_good ../quality2/${file%.fastq}_quality \
-out_bad null \
-min_len 120 \
-ns_max_n 0 \
-min_qual_mean 30 \
-out_format 3 \
-trim_left 17 \
-trim_to_len 160 2> ../quality2/${file%.fastq}_log.txt
done
```

Keeps about 40-60% of reads and trims the mall to 160bp

## merge all reads and convert from fastq to fna
```
cat *.fastq > merged.fastq
sed '/^@/!d;s//>/;N' merged.fastq > merged.fasta
```

## fix the names to type that qiime wants with custom python script
```
import sys
i = 1
with open(sys.argv[1], 'r') as file:
	for line in file:
		if line[0] == ">":
			linesplit = line.split()
			id = linesplit[-1].split(":")[-1].strip()
			print(">" + id + '_' + str(i) + ' ' + linesplit[0][1:])
			i += 1
		else:
			print(line.strip())
```

## Pick otus
Using Swarm as the algorithm
For now needs to be don on macqiime
```
pick_otus.py -i merged_fixed2.fna -m swarm -o swarm_otus2
Default Swarm parameters is d=1 (1 bp difference for clusters)
Tried a range of d values to see where d should be set naturally.
d=1: 99,000 OTUs
d=2: 32,790 OTUs
d=3: 12,851 OTUs
d=5: 4,274 OTUs
d=8: 2,810 OTUs
d=10: 2,670 OTUs

Using d=8 for OTU picking

```

## Filter low abundance OTUs

Want to filter out OTUs that only have one hit
number of OTUs went from 99,038 to 1,787 USING D1
Now using d=8
Number of OTUs went from 2,810 to 212
The problem with using this command:
filter_otus_from_otu_table.py -i otu_table_tax.biom -n 2 -o filtered_otu_table
is that it only works on biom table, not the OTU map. pick_rep_set.yp picks from the OTU map generated by pick_otus.py so I need a way to filter that.
Using custon python script to filter OTU map. The first input is an OTU map from pick_otus.py and the second input is the minimum number of sequences in all samples for OTU to be kept.
```
import sys

MINIMUM = int(sys.argv[2])

with open(sys.argv[1], 'r') as file:
	for line in file:
		linesplit = line.split()
		if len(linesplit) -1 >= MINIMUM:
			print(line.strip())
```
The using the script with this command:
```
python filter_otu_map.py merged_fixed2_otus_d8.txt 2 > d8_filtered_otu_map.txt
```

##Pick representative sequence for each OTU
pick_rep_set.py -i d8_filtered_otu_map.txt -f merged_fixed2.fna -o filtered_rep_set.fna

## Assign Taxonomy
Using the defaults from qiime
**Parameters**
UclustConsensusTaxonAssigner parameters:
id_to_taxonomy_filepath:/macqiime/greengenes/gg_13_8_otus/taxonomy/97_otu_taxonomy.txt
id_to_taxonomy_fp:/macqiime/greengenes/gg_13_8_otus/taxonomy/97_otu_taxonomy.txt
max_accepts:3
min_consensus_fraction:0.51
reference_sequences_fp:/macqiime/greengenes/gg_13_8_otus/rep_set/97_otus.fasta
similarity:0.9
unassignable_label:Unassigned
Result path: /tmp/assign-tax9PNK_V

.uc file contents:
```
# uclust --input merged_fixed2.fna_rep_set.fasta --id 0.9 --rev --maxaccepts 3 --allhits --libonly --lib /macqiime/greengenes/gg_13_8_otus/rep_set/97_otus.fasta --uc /tmp/UclustConsensusTaxonAssigner_JdaNux.uc
# version=1.2.22
# Tab-separated fields:
# 1=Type, 2=ClusterNr, 3=SeqLength or ClusterSize, 4=PctId, 5=Strand, 6=QueryStart, 7=SeedStart, 8=Alignment, 9=QueryLabel, 10=TargetLabel
# Record types (field 1): L=LibSeed, S=NewSeed, H=Hit, R=Reject, D=LibCluster, C=NewCluster, N=NoHit
# For C and D types, PctId is average id with seed.
# QueryStart and SeedStart are zero-based relative to start of sequence.
# If minus strand, SeedStart is relative to reverse-complemented seed.
```

```
assign_taxonomy.py -i filtered_rep_set.fna
```

## Make OTU table
For now needs to be don on macqiime
```
make_otu_table.py -i d8_filtered2_otu_map.txt -m Map2.txt -t uclust_assigned_taxonomy/filtered_rep_set_tax_assignments.txt -o d8_otu_table.biom
```


## Make txt OTU table
```
biom convert -i d8_otu_table.biom -o d8_otu_table.txt --to-tsv --table-type="OTU table" --header-key taxonomy
```

## Quick look at taxonomy barplots
Optional but nice to see that everything worked
```
summarize_taxa_through_plots.py -i otu_table_filtered.biom -o taxa_summary
summarize_taxa_through_plots.py -i otu_table_filtered.biom -o taxa_summary2 -m Map2.txt -c Patient
```

## Rarefaction
First filter controls from OTU table

```
filter_samples_from_otu_table.py -i d8_otu_table.biom -o d8_otu_table_nc.biom -m Map2.txt --sample_id_fp remove_samples.txt --negate_sample_id_fp
```

Rarefy to sample with lowest number of reads. Perform 10 rarefactions.
```
multiple_rarefactions_even_depth.py -i d8_otu_table_nc.biom -o rarefaction -d 2700
```
Make txt OTU talbe for rarefactions
```
for file in *.biom
do 
biom convert -i ${file} -o ${file%.biom}.txt --to-tsv --table-type="OTU table"
done
```

## Unifrac distances
Calculate Unifrac distances based on phylogeny

### align sequences
```
align_seqs.py -i filtered_rep_set.fna -o filtered_rep_set_alignment
```

### Make phylogeny
```
make_phylogeny.py -i rep_set_pynast_aligned/merged_fixed2.fna_rep_set_aligned.fasta
```

### Calculate beta diversity

Do for no rarefaction and for each rarefaction\
You can either input a .biom file or a directory with bioom files\
Do weighted and unweighted unifracs
```
beta_diversity.py -i d8_otu_table_nc.biom -t filtered_rep_set_alignment/filtered_rep_set_aligned.tre -o beta
beta_diversity.py -i rarefaction -t filtered_rep_set_alignment/filtered_rep_set_aligned.tre -o beta_rare
```

### Calculate alpha diversity
For non-rarefied sample\
Using metrics: shannon,simpson, chao1,pd_whole_tree
```
alpha_diversity.py -i d8_otu_table_nc.biom -o alpha_norare -m shannon,simpson,chao1,PD_whole_tree -t filtered_rep_set_alignment/filtered_rep_set_aligned.tre
```
For rarefied samples
```
alpha_diversity.py -i rarefaction -o alpha -m shannon,simpson,chao1,PD_whole_tree -t filtered_rep_set_alignment/filtered_rep_set_aligned.tre
```